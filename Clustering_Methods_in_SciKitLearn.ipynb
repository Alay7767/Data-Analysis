{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d763e3-2067-429f-80a6-619fe78ca52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterID\n",
      "0    [Saudi Arabia, Canada, Spain, Singapore, Cypru...\n",
      "1    [Pakistan, Nigeria, Niger, Nepal, Namibia, Mya...\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import pandas as AP\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import numpy as BP\n",
    "\n",
    "cD = AP.read_csv(\"C:\\\\Users\\\\alayp\\\\Downloads\\\\archive\\\\Country-data.csv\")\n",
    "cN = cD.iloc[:, 0]\n",
    "d = cD.iloc[:, 1:].values\n",
    "\n",
    "# K = 1\n",
    "km = KMeans(n_clusters=2, random_state=0, n_init=\"auto\")\n",
    "km.fit(d)\n",
    "clusterIds = km.labels_\n",
    "\n",
    "countryWithClusterID = AP.DataFrame({\n",
    "    'Country': cN,\n",
    "    'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID = countryWithClusterID.sort_values(by='ClusterID')\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "\n",
    "clusteredCountryData = AP.read_csv('clusteredCountries.csv')\n",
    "g = clusteredCountryData.groupby('ClusterID')['Country'].apply(list)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34001161-517f-42d8-91ba-6b9906cbf3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterID\n",
      "0             [Norway, Qatar, Luxembourg, Switzerland]\n",
      "1    [Afghanistan, Mauritania, Mauritius, Micronesi...\n",
      "2    [Belgium, Iceland, Netherlands, Bahamas, Kuwai...\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# K = 3\n",
    "km = KMeans(n_clusters=3, random_state=0, n_init=\"auto\")\n",
    "km.fit(d)\n",
    "clusterIds = km.labels_\n",
    "\n",
    "countryWithClusterID = AP.DataFrame({\n",
    "    'Country': cN,\n",
    "    'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID = countryWithClusterID.sort_values(by='ClusterID')\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "\n",
    "clusteredCountryData = AP.read_csv('clusteredCountries.csv')\n",
    "g = clusteredCountryData.groupby('ClusterID')['Country'].apply(list)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9577507e-7004-4215-91f4-46326edeb32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterID\n",
      "0                          [Norway, Luxembourg, Qatar]\n",
      "1    [Mali, Mauritania, Mauritius, Micronesia, Fed....\n",
      "2    [Iceland, United States, Singapore, Japan, Uni...\n",
      "3    [Romania, Libya, Lithuania, Turkey, Equatorial...\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# K = 4\n",
    "km = KMeans(n_clusters=4, random_state=0, n_init=\"auto\")\n",
    "km.fit(d)\n",
    "clusterIds = km.labels_\n",
    "\n",
    "countryWithClusterID = AP.DataFrame({\n",
    "    'Country': cN,\n",
    "    'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID = countryWithClusterID.sort_values(by='ClusterID')\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "\n",
    "clusteredCountryData = AP.read_csv('clusteredCountries.csv')\n",
    "g = clusteredCountryData.groupby('ClusterID')['Country'].apply(list)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f111f54b-684c-496b-aceb-a20e33f50920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterID\n",
      "0                          [Norway, Luxembourg, Qatar]\n",
      "1    [Romania, Estonia, Turkey, Russia, Kazakhstan,...\n",
      "2    [Iceland, Ireland, Japan, Singapore, Kuwait, G...\n",
      "3    [Saudi Arabia, United Kingdom, Italy, Bahrain,...\n",
      "4    [Tanzania, Solomon Islands, Paraguay, Sri Lank...\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# K = 5\n",
    "km = KMeans(n_clusters=5, random_state=0, n_init=\"auto\")\n",
    "km.fit(d)\n",
    "clusterIds = km.labels_\n",
    "\n",
    "countryWithClusterID = AP.DataFrame({\n",
    "    'Country': cN,\n",
    "    'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID = countryWithClusterID.sort_values(by='ClusterID')\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "\n",
    "clusteredCountryData = AP.read_csv('clusteredCountries.csv')\n",
    "g = clusteredCountryData.groupby('ClusterID')['Country'].apply(list)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e4f1b3b-1b76-430e-8e56-f876e24ff8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterID\n",
      "0                          [Qatar, Norway, Luxembourg]\n",
      "1    [Croatia, Chile, Colombia, Suriname, Costa Ric...\n",
      "2    [Finland, Iceland, Australia, Netherlands, Swi...\n",
      "3    [Israel, Italy, Malta, Oman, Czech Republic, B...\n",
      "4    [Peru, Nigeria, Pakistan, Niger, Paraguay, Afg...\n",
      "5    [Brunei, United Arab Emirates, Singapore, Kuwait]\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# K = 6\n",
    "km = KMeans(n_clusters=6, random_state=0, n_init=\"auto\")\n",
    "km.fit(d)\n",
    "clusterIds = km.labels_\n",
    "\n",
    "countryWithClusterID = AP.DataFrame({\n",
    "    'Country': cN,\n",
    "    'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID = countryWithClusterID.sort_values(by='ClusterID')\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "\n",
    "clusteredCountryData = AP.read_csv('clusteredCountries.csv')\n",
    "g = clusteredCountryData.groupby('ClusterID')['Country'].apply(list)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf92fd15-f633-4dfc-8af8-a11c98db0e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k=2, the countries are split into two groups: one with wealthier countries and one with less wealthy countries.\n",
      "With k=3, a third group is added for countries that are somewhere in the middle—not too rich, not too poor.\n",
      "With k=4, another group is created for countries that have a mix of both rich and poor traits, but the richer countries still stay grouped together.\n",
      "With k=5, the countries are split into five groups: rich, somewhat rich, middle, somewhat poor, and poor.\n"
     ]
    }
   ],
   "source": [
    "print(\"With k=2, the countries are split into two groups: one with wealthier countries and one with less wealthy countries.\")\n",
    "\n",
    "print(\"With k=3, a third group is added for countries that are somewhere in the middle—not too rich, not too poor.\")\n",
    "\n",
    "print(\"With k=4, another group is created for countries that have a mix of both rich and poor traits, but the richer countries still stay grouped together.\")\n",
    "\n",
    "print(\"With k=5, the countries are split into five groups: rich, somewhat rich, middle, somewhat poor, and poor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30cea2d1-4018-4366-9433-ba4283d19419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterID\n",
      "0    [Afghanistan, Moldova, Mongolia, Montenegro, M...\n",
      "1    [Kuwait, Ireland, Netherlands, United States, ...\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative K = 2\n",
    "clustering = AgglomerativeClustering(n_clusters=2)\n",
    "clustering.fit(d)\n",
    "clusterIds = clustering.labels_\n",
    "countryWithClusterID = AP.DataFrame({\n",
    " 'Country': cN,\n",
    " 'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID = countryWithClusterID.sort_values(by='ClusterID')\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "clusteredCountryData = AP.read_csv('clusteredCountries.csv')\n",
    "g = clusteredCountryData.groupby('ClusterID')['Country'].apply(list)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fad85be-c4ac-4c40-bd50-c2d7631d87ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterID\n",
      "0    [Canada, Japan, France, Finland, Singapore, No...\n",
      "1    [Cyprus, Czech Republic, Hungary, Argentina, S...\n",
      "2    [Afghanistan, Nigeria, Niger, Nepal, Namibia, ...\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative K = 3\n",
    "clustering = AgglomerativeClustering(n_clusters=3)\n",
    "clustering.fit(d)\n",
    "clusterIds = clustering.labels_\n",
    "countryWithClusterID = AP.DataFrame({\n",
    " 'Country': cN,\n",
    " 'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID = countryWithClusterID.sort_values(by='ClusterID')\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "clusteredCountryData = AP.read_csv('clusteredCountries.csv')\n",
    "g = clusteredCountryData.groupby('ClusterID')['Country'].apply(list)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77c80b3-736a-4145-8fd8-8764fa385b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterID\n",
      "0    [Netherlands, Canada, France, Finland, Brunei,...\n",
      "1             [Qatar, Switzerland, Norway, Luxembourg]\n",
      "2    [Morocco, Mozambique, Myanmar, Montenegro, Mon...\n",
      "3    [Croatia, Barbados, Cyprus, Turkey, Bahrain, B...\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative K = 4\n",
    "clustering = AgglomerativeClustering(n_clusters=4)\n",
    "clustering.fit(d)\n",
    "clusterIds = clustering.labels_\n",
    "countryWithClusterID = AP.DataFrame({\n",
    " 'Country': cN,\n",
    " 'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID = countryWithClusterID.sort_values(by='ClusterID')\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "clusteredCountryData = AP.read_csv('clusteredCountries.csv')\n",
    "g = clusteredCountryData.groupby('ClusterID')['Country'].apply(list)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7001ca4f-8369-4b1a-b3c9-0df5b8b7daed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterID\n",
      "0             [Luxembourg, Switzerland, Norway, Qatar]\n",
      "1    [Czech Republic, Chile, Slovak Republic, Seych...\n",
      "2    [Namibia, Mozambique, Nepal, Ukraine, Morocco,...\n",
      "3    [Finland, France, Denmark, Australia, United S...\n",
      "4    [United Arab Emirates, Brunei, Kuwait, Singapore]\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative K = 5\n",
    "clustering = AgglomerativeClustering(n_clusters=5)\n",
    "clustering.fit(d)\n",
    "clusterIds = clustering.labels_\n",
    "countryWithClusterID = AP.DataFrame({\n",
    " 'Country': cN,\n",
    " 'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID = countryWithClusterID.sort_values(by='ClusterID')\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "clusteredCountryData = AP.read_csv('clusteredCountries.csv')\n",
    "g = clusteredCountryData.groupby('ClusterID')['Country'].apply(list)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95b66212-edf6-4190-8772-f74259d17b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As we increase the number of clusters, countries start to group based on how developed they are.\n",
      " Rich, developed countries end up in different groups from poorer, developing ones.\n",
      " The clusters also reflect some regional and economic similarities.\n",
      " For example, with k=2, one group has mostly wealthy countries, and the other has developing nations.\n",
      " With k=5, the richest countries are in one group, while smaller but still wealthy countries form their own group.\n"
     ]
    }
   ],
   "source": [
    "print(\"As we increase the number of clusters, countries start to group based on how developed they are.\\n Rich, developed countries end up in different groups from poorer, developing ones.\\n The clusters also reflect some regional and economic similarities.\\n For example, with k=2, one group has mostly wealthy countries, and the other has developing nations.\\n With k=5, the richest countries are in one group, while smaller but still wealthy countries form their own group.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16c462ec-81a6-44ae-b2ee-310ead8fb6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters (excluding noise): 5\n",
      "Number of noise points: 84\n",
      "DBSCAN is good at finding clusters that aren’t perfectly shaped and can deal with outliers by labeling them as noise (with -1).\n",
      " On the other hand, KMeans and Agglomerative Clustering always force the data into a set number of groups, even if some points don’t really belong, which can lead to odd or unrealistic groupings.\n",
      "DBSCAN is more flexible because it can find clusters of different shapes and ignore data points that don’t really fit anywhere.\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=800, min_samples=3)\n",
    "clusterIds = dbscan.fit_predict(d)\n",
    "uC = len(set(clusterIds)) - (1 if -1 in clusterIds else 0)\n",
    "nP = list(clusterIds).count(-1)\n",
    "sortedCountryWithClusterID = AP.DataFrame({\n",
    " 'Country': cN,\n",
    " 'ClusterID': clusterIds\n",
    "})\n",
    "sortedCountryWithClusterID.to_csv('clusteredCountries.csv', index=False)\n",
    "print(f\"Number of clusters (excluding noise): {uC}\")\n",
    "print(f\"Number of noise points: {nP}\")\n",
    "print(\"DBSCAN is good at finding clusters that aren’t perfectly shaped and can deal with outliers by labeling them as noise (with -1).\\n On the other hand, KMeans and Agglomerative Clustering always force the data into a set number of groups, even if some points don’t really belong, which can lead to odd or unrealistic groupings.\")\n",
    "print(\"DBSCAN is more flexible because it can find clusters of different shapes and ignore data points that don’t really fit anywhere.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29fedca6-d2ca-4054-ba3e-50b252a5feb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running DBSCAN with eps = 700 and min_samples = 2\n",
      "Clusters (no noise): 11\n",
      "Noise points: 74\n",
      "\n",
      "\n",
      "Running DBSCAN with eps = 700 and min_samples = 3\n",
      "Clusters (no noise): 6\n",
      "Noise points: 84\n",
      "\n",
      "\n",
      "Running DBSCAN with eps = 800 and min_samples = 2\n",
      "Clusters (no noise): 14\n",
      "Noise points: 66\n",
      "\n",
      "\n",
      "Running DBSCAN with eps = 800 and min_samples = 3\n",
      "Clusters (no noise): 5\n",
      "Noise points: 84\n",
      "\n",
      "\n",
      "Running DBSCAN with eps = 900 and min_samples = 2\n",
      "Clusters (no noise): 14\n",
      "Noise points: 60\n",
      "\n",
      "\n",
      "Running DBSCAN with eps = 900 and min_samples = 3\n",
      "Clusters (no noise): 7\n",
      "Noise points: 74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run DBSCAN for epsilon values: [700, 800,900] and min_samples values: [2,3].\n",
    "# You can do that by writing two nested for loops of this form:\n",
    "import pandas as AP\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "d = pd.read_csv(\"C:\\\\Users\\\\alayp\\\\Downloads\\\\archive\\\\Country-data.csv\")\n",
    "cnam = d.iloc[:, 0]\n",
    "vals = d.iloc[:, 1:].values\n",
    "\n",
    "for eps in range(700, 1000, 100):\n",
    "    for mins in range(2, 4, 1):\n",
    "        print(f\"\\nRunning DBSCAN with eps = {eps} and min_samples = {mins}\")\n",
    "        \n",
    "        dbs = DBSCAN(eps=eps, min_samples=mins)\n",
    "        clid = dbs.fit_predict(vals)\n",
    "\n",
    "        ncls = len(set(clid)) - (1 if -1 in clid else 0)\n",
    "        nnoi = list(clid).count(-1)\n",
    "\n",
    "        df = AP.DataFrame({\n",
    "            'Cntry': cnam,\n",
    "            'CID': clid\n",
    "        })\n",
    "        df.to_csv(f'clust_eps{eps}_min{mins}.csv', index=False)\n",
    "\n",
    "        print(f\"Clusters (no noise): {ncls}\")\n",
    "        print(f\"Noise points: {nnoi}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e6191d6-160b-4444-92a7-5689d5c690a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing the eps (distance between points) and min_samples (minimum points to form a group) doesn’t make much difference because the clusters in the data are already clear.\n",
      " These settings aren’t sensitive enough to change how the countries are grouped, so even when you tweak them, you still get the same clusters and noise points.\n"
     ]
    }
   ],
   "source": [
    "print(\"Changing the eps (distance between points) and min_samples (minimum points to form a group) doesn’t make much difference because the clusters in the data are already clear.\\n These settings aren’t sensitive enough to change how the countries are grouped, so even when you tweak them, you still get the same clusters and noise points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f40751-2673-49b4-8d40-1201f7c27a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
