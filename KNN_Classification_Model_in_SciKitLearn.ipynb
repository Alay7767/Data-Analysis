{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "097302d5-f10b-4069-97b8-821bb5b71704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as sd\n",
    "import sklearn.neighbors as sn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6b50156-a146-49b1-b570-6971e5345e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "(X,y) = sd.load_svmlight_file(\"C:\\\\Users\\\\alayp\\\\Downloads\\\\colon_cancer_train_1.libsvm\")\n",
    "(X_test,y_test) = sd.load_svmlight_file(\"C:\\\\Users\\\\alayp\\\\Downloads\\\\colon_cancer_test_1.libsvm\")\n",
    "ap_knn = sn.KNeighborsClassifier(n_neighbors=3)\n",
    "ap_knn.fit(X,y)\n",
    "a = ap_knn.score(X_test,y_test)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d57a7c33-b7e0-4f35-835e-9cfe1ec78bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Accuracy is 0.782608695652174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe729188-6a65-4acf-8d71-f5459b4eaa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors = 3, metric = 'cityblock', accuracy = 0.7826\n",
      "n_neighbors = 3, metric = 'cosine', accuracy = 0.8261\n",
      "n_neighbors = 3, metric = 'euclidean', accuracy = 0.7826\n",
      "n_neighbors = 3, metric = 'l1', accuracy = 0.7826\n",
      "n_neighbors = 3, metric = 'l2', accuracy = 0.7826\n",
      "n_neighbors = 3, metric = 'manhattan', accuracy = 0.7826\n",
      "n_neighbors = 5, metric = 'cityblock', accuracy = 0.8696\n",
      "n_neighbors = 5, metric = 'cosine', accuracy = 0.8696\n",
      "n_neighbors = 5, metric = 'euclidean', accuracy = 0.8696\n",
      "n_neighbors = 5, metric = 'l1', accuracy = 0.8696\n",
      "n_neighbors = 5, metric = 'l2', accuracy = 0.8696\n",
      "n_neighbors = 5, metric = 'manhattan', accuracy = 0.8696\n",
      "n_neighbors = 7, metric = 'cityblock', accuracy = 0.9130\n",
      "n_neighbors = 7, metric = 'cosine', accuracy = 0.8696\n",
      "n_neighbors = 7, metric = 'euclidean', accuracy = 0.8696\n",
      "n_neighbors = 7, metric = 'l1', accuracy = 0.9130\n",
      "n_neighbors = 7, metric = 'l2', accuracy = 0.8696\n",
      "n_neighbors = 7, metric = 'manhattan', accuracy = 0.9130\n",
      "n_neighbors = 9, metric = 'cityblock', accuracy = 0.8696\n",
      "n_neighbors = 9, metric = 'cosine', accuracy = 0.8696\n",
      "n_neighbors = 9, metric = 'euclidean', accuracy = 0.8261\n",
      "n_neighbors = 9, metric = 'l1', accuracy = 0.8696\n",
      "n_neighbors = 9, metric = 'l2', accuracy = 0.8261\n",
      "n_neighbors = 9, metric = 'manhattan', accuracy = 0.8696\n",
      "n_neighbors = 11, metric = 'cityblock', accuracy = 0.8261\n",
      "n_neighbors = 11, metric = 'cosine', accuracy = 0.7826\n",
      "n_neighbors = 11, metric = 'euclidean', accuracy = 0.8696\n",
      "n_neighbors = 11, metric = 'l1', accuracy = 0.8261\n",
      "n_neighbors = 11, metric = 'l2', accuracy = 0.8696\n",
      "n_neighbors = 11, metric = 'manhattan', accuracy = 0.8261\n"
     ]
    }
   ],
   "source": [
    "m = sorted(sn.VALID_METRICS_SPARSE[\"brute\"])\n",
    "m = [i for i in m if i != \"precomputed\"]\n",
    "n = [3, 5, 7, 9, 11]\n",
    "r = []\n",
    "apMaxTestAccuracy = 0\n",
    "apMaxTrainAccuracy = 0\n",
    "apBestTestParams = None\n",
    "apBestTrainParams = None\n",
    "for x in n:\n",
    " for i in m:\n",
    "    \n",
    "     ap_knn = sn.KNeighborsClassifier(n_neighbors=x, metric=i)\n",
    "\n",
    "     ap_knn.fit(X, y)\n",
    "\n",
    "     ap_y_pred = ap_knn.predict(X_test)\n",
    "\n",
    "     a = accuracy_score(y_test, ap_y_pred)\n",
    "\n",
    "     r.append((x, i, a))\n",
    "     y_train_pred = ap_knn.predict(X)\n",
    "\n",
    "     apTestAccuracy = accuracy_score(y_test, ap_y_pred)\n",
    "     apTrainAccuracy = accuracy_score(y, y_train_pred)\n",
    "\n",
    "     if apTestAccuracy > apMaxTestAccuracy:\n",
    "         apMaxTestAccuracy = apTestAccuracy\n",
    "         apBestTestParams = (x, i)\n",
    "\n",
    "     if apTrainAccuracy > apMaxTrainAccuracy:\n",
    "         apMaxTrainAccuracy = apTrainAccuracy\n",
    "         apBestTrainParams = (x, i)\n",
    "for x, i, a in r:\n",
    " print(f\"n_neighbors = {x}, metric = '{i}', accuracy = {a:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb367328-1833-417f-8fca-9ab467f6e7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1. Maximum accuracy on the test set is 0.9130,\n",
      " Parameters n_neighbors = 7, \n",
      " Metric = cityblock\n",
      "\n",
      "Q2. Maximum accuracy on the training set is 0.8205,\n",
      " Parameters n_neighbors = 3, \n",
      " Metric = cityblock\n",
      "\n",
      "Q3. The training and test sets have different ideal characteristics.\n",
      "\n",
      "Q4.  Overfitting or underfitting may be indicated if the ideal parameters for the training and test sets disagree. A model is said to be overfit if it does effectively with training data but inefficiently on test data, and underfit if it is overly simplistic and scores poorly on both.\n"
     ]
    }
   ],
   "source": [
    "# Question/Answer\n",
    "\n",
    "print(f\"Q1. Maximum accuracy on the test set is {apMaxTestAccuracy:.4f},\\n Parameters n_neighbors = {apBestTestParams[0]}, \\n Metric = {apBestTestParams[1]}\\n\")\n",
    "print(f\"Q2. Maximum accuracy on the training set is {apMaxTrainAccuracy:.4f},\\n Parameters n_neighbors = {apBestTrainParams[0]}, \\n Metric = {apBestTrainParams[1]}\\n\")\n",
    "if apBestTestParams == apBestTrainParams:\n",
    " print(\"Q3. The training and test sets' ideal parameters are identical.\\n\")\n",
    "else:\n",
    " print(\"Q3. The training and test sets have different ideal characteristics.\\n\")\n",
    "\n",
    "print(\"Q4.  Overfitting or underfitting may be indicated if the ideal parameters for the training and test sets disagree. A model is said to be overfit if it does effectively with training data but inefficiently on test data, and underfit if it is overly simplistic and scores poorly on both.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1444f3-24f7-409f-9b86-a7aa8cd79d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
